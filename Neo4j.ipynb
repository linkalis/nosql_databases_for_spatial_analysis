{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Neo4j for Spatial Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction & background on Neo4j and graph databases..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch Neo4j locally using Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a persistent data volume\n",
    "\n",
    "To get started, you'll need to create a persistent data volume that Docker can use to store your database's files.  Creating a Docker volume allows you to persist any data loaded into the database, even if you have to stop, start, or re-run the Docker container housing your database.  Run the following from the command line to create a Docker volume for you Neo4j database:\n",
    "\n",
    "```bash\n",
    "docker volume create neo4j_volume\n",
    "```\n",
    "\n",
    "To check that the volume was created successfully, run the following from your command line:\n",
    "```bash\n",
    "docker volume ls\n",
    "```\n",
    "\n",
    "You should see a volume called `neo4j_volume` listed in the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download database plugins\n",
    "\n",
    "Neo4j has a number of community-supported plugins that provide useful utilities for loading data, running advanced graph algorithms, and managing spatial data.  Download the latest release of each of these plugins from their respective GitHub pages:\n",
    "\n",
    "- Awesome Procedures for Neo4j (APOC): \n",
    "[[Download link](https://github.com/neo4j-contrib/neo4j-apoc-procedures/releases)]\n",
    "[[GitHub main page](https://github.com/neo4j-contrib/neo4j-apoc-procedures)]\n",
    "[[Documentation](https://neo4j-contrib.github.io/neo4j-apoc-procedures/)]\n",
    "\n",
    "- Efficient Graph Algorithms for Neo4j: \n",
    "[[Download link](https://github.com/neo4j-contrib/neo4j-graph-algorithms/releases)]\n",
    "[[GitHub main page](https://github.com/neo4j-contrib/neo4j-graph-algorithms)]\n",
    "[[Documentation](https://neo4j.com/docs/graph-algorithms/current/)]\n",
    "\n",
    "- Neo4j Spatial: \n",
    "[[Download link](https://github.com/neo4j-contrib/spatial/releases)]\n",
    "[[GitHub main page](https://github.com/neo4j-contrib/spatial)]\n",
    "[[User Guide](https://neo4j-contrib.github.io/spatial/)]\n",
    "\n",
    "\n",
    "Each of these plugins downloads as a .jar file.  Take these .jar files and move them to a folder on your computer where you can find them easily.  For this example, we'll assume you're saving them to your user folder inside of a folder called 'neo4j_plugins':\n",
    "\n",
    "/Users/your_username/neo4j_plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the Docker container\n",
    "\n",
    "Now you're finally ready to launch Neo4j using Docker!  Run the following from your command line.  Be sure to replace the file path in brackets (<>) below with the actual path to your neo4j_plugins folder (and remove the brackets):\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "--name neo4j \\\n",
    "-p 7474:7474 -p 7687:7687 \\\n",
    "--mount source=neo4j_volume,target=/data \\\n",
    "-v </Users/your_username/neo4j_plugins>:/plugins \\\n",
    "-e NEO4J_apoc_export_file_enabled=true \\\n",
    "-e NEO4J_apoc_import_file_enabled=true \\\n",
    "-e NEO4J_apoc_import_file_use__neo4j__config=true \\\n",
    "-e NEO4J_dbms_security_procedures_unrestricted=apoc.\\\\\\*,algo.\\\\\\*,spatial.\\\\\\* \\\n",
    "-e NEO4J_dbms_security_allow__csv__import__from__file__urls=true \\\n",
    "neo4j:3.4\n",
    "```\n",
    "\n",
    "What does this command do?  Breaking it down, here's what each argument means:\n",
    "\n",
    "- **-d** : runs the container in \"detached\" mode, so that it keeps running in the background and will not shut off if you close out of your console window\n",
    "- **--name** : the name Docker will give to your container; if you don't specify a name here, Docker will give your container a randomly-generated name\n",
    "- **-p** : these are port mappings, indicating that Docker should forward information going in and out of port 7474 from the Neo4j container to port 7474 on your local machine; the same goes for port 7687\n",
    "- **--mount** : takes the persistent volume named `neo4j_volume` and mounts it into the /data folder inside of the container; this is where the database's data and settings will get stored\n",
    "- **-e**: environment variables that get passed to the database's configuration file on startup; these variables are required to make sure plugins will run correctly\n",
    "- At the very end of the command, you'll notice we list **neo4j:3.4** as the final argument.  This specifies the Docker image and version to run inside of the container, and will download and launch Neo4j version 3.4 (the most current version as of this writing).  If newer versions are available, you can specify `neo4j:latest` to get the most recent version of Neo4j.\n",
    "\n",
    "To check that the container is running, execute the following command in the command line:\n",
    "\n",
    "```docker container ls```\n",
    "\n",
    "You should see something like this, indicating that the container is successfully running:\n",
    "\n",
    "```\n",
    "CONTAINER ID    IMAGE        COMMAND                CREATED         STATUS          PORTS\n",
    "blahblahblah    neo4j:3.4    \"/sbin/tini -g -- /dâ€¦\" 9 seconds ago   Up 8 seconds    0.0.0.0:7474->7474/tcp, 7473/tcp, 0.0.0.0:7687->7687/tcp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neo4j has a web-based access interface that you can view using a web browser.  Launch your web browser of choice and navigate to:\n",
    "\n",
    "```http://localhost:7474/browser```\n",
    "\n",
    "If the container is successfully initialized, you should be able to see a login interface in your web browser.  It will prompt you for a username and password.  Enter ```neo4j``` as both your username and password:\n",
    "\n",
    "![Neo4j browser launch page](img_neo4j/neo4j_browser_launch.png)\n",
    "\n",
    "Then, reset the default admit password to a new password of your choice when prompted:\n",
    "\n",
    "![Neo4j browser launch page password setup](img_neo4j/neo4j_browser_launch_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into the database\n",
    "\n",
    "Now, it's almost time to load in some data!  Because it is a graph database, Neo4j requires a little consideration of how to structure the data into **nodes** and their **relationships** (sometimes called \"edges\").  Nodes are the _things_ we want to represent.  For this example, the node types will be: \"tweets\", \"users\", \"places\", and \"hashtags\".  Relationships are the _linkages_ we want to represent between nodes.  For this example, we'll define relationships such as: \"tweeted by\", \"located in\", \"mentions\", etc.  Both nodes and relationships can contain attributes that describe them in further detail.  Together, nodes and edges and the properties that describe them represent the fundamental building blocks of a \"property graph\" data structure.  \n",
    "\n",
    "Here's a sketch of the data model we'll use when loading tweets into Neo4j:\n",
    "<img src=\"img_neo4j/neo4j_data_model.png\" alt=\"Neo4j tweet data model\" style=\"width: 600px; height: 500px\"/>\n",
    "Don't worry if the data structure doesn't feel totally comprehensive.  The big advantage of a graph database like Neo4j is that it's easy to add additional relationships between nodes at any time via simple queries if you want to add additional structure to your data later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create indexes\n",
    "\n",
    "Prior to loading in any data, let's prepare the database by adding some indexes.  Adding indexes is a critical step, because the presence of indexes can really help improve load time.  We also want to do our best not to load duplicate data when adding data to the database, and indexes can help with this.  When loading in data, we will ask Neo4j to check for any duplicates of tweets, users, places, or hashtags that may be present prior to loading in new records.  If it encounters a tweet that is already present in the database, Neo4j can skip over this tweet and avoid loading a redundant record.  In order to check for duplicates, however, Neo4j first needs to search through all of the existing records on each record load to see what's already present in the database.  This search and insert process goes _much_ more quickly if data is pre-sorted using indexes.  \n",
    "\n",
    "_What happens if we don't add indexes before loading in the data?_  Here is an example of 40 files being loaded into Neo4j installed on a home server.  In this scenario, the first 20 files were loaded prior to the addition of indexes, and the last 20 files were loaded after the addition of indexes:  \n",
    "\n",
    "![visualization of load time before and after adding indexes](img_neo4j/neo4j_load_time_indexes.png)\n",
    "\n",
    "Some of the load time depicted above is due to network latency and processing effort required in the database, but much of the load time can be attributed to the relative efficiency or ineffeciency due to the presence or absence of indexes.  For the first 20 files, you can see that the load time increases at a linear rate, with each file taking consistently longer to load.  For the last 20 files, you can see that the load time immediately drops after the addition of the indexes and stays more consistently flat, regardless of how many additional files we load.\n",
    "\n",
    "To create an index, run the following command in the web admin console for your Neo4j instance.  Copy the command into the console, and then click the \"play\" button to execute the command: \n",
    "\n",
    "```cypher\n",
    "CREATE INDEX ON :Tweet(tweet_id)\n",
    "```\n",
    "\n",
    "![Neo4j create index call](img_neo4j/neo4j_create_index.png)\n",
    "\n",
    "The above command created an index on tweet_id, which is the unique identifier we'll be using to load tweets and check for duplicates.  Next, create an index on user_id, place_id, and hashtag_id to function in a similar manner.  Execute these commands one by one in the Neo4j web admin console:\n",
    "\n",
    "```cypher\n",
    "CREATE INDEX ON :User(user_id)\n",
    "CREATE INDEX ON :Place(place_id)\n",
    "CREATE INDEX ON :Hashtag(hashtag_id)\n",
    "```\n",
    "\n",
    "Finally, add a spatial index for the centroids of the Twitter Places that are present in our tweets.  This will enable some basic spatial query functionality after the data is loaded:\n",
    "\n",
    "```cypher\n",
    "CREATE INDEX ON :Place(centroid)\n",
    "```\n",
    "\n",
    "To check that the indexes have been successfully created, run the following:\n",
    "```cypher\n",
    "CALL db.indexes\n",
    "```\n",
    "\n",
    "![Neo4j results for CALL db.indexes](img_neo4j/neo4j_indexes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute load scripts\n",
    "\n",
    "Now it's time to load in the data.  The demo data comes in the form of .txt files that have been split into chunks of ~5000 tweets per file.  Each line of each file is formatted as a JSON object representing a single tweet, and each tweet is separated by a newline within the .txt files.  To make loading easier, this repository contains a pre-baked script you can use to load data into Neo4j.  The script cleans the tweet data's geographic components and also coerces the data to conform to the basic data model described above as it is loaded into Neo4j.  Run the following code to import the script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Clean_Load_Scripts as cleanNLoad\n",
    "import secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define a variable called `data_folder` that points to the location of the demo data on your computer.  Also define a variable called `logs_folder` that points to the path where you want to store log files about the load.  This folder can be located directly inside of your data folder, or it can be an entirely separate path.  The load script will keep track of files that need to be loaded, load time for each file, error counts, and some other diagnostic data for each file as it loads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = '/Users/linkalis/Desktop/twitter_data/data_small_5000_split/'\n",
    "logs_folder = '/Users/linkalis/Desktop/twitter_data/data_small_5000_split/logs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it will ~30 seconds to load each file, so be ready grab a coffee and be patient.  Because you have already added indexes, and because the data is being loaded to your localhost machine and doesn't have to travel across a network, this should keep the load time relatively flat.  This is about what you should expect:\n",
    "\n",
    "![Neo4j load times in Docker running on localhost](img_neo4j/neo4j_load_time_docker_localhost.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, initialize the extractor to kick off the load logs and prep the files for load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extractor = cleanNLoad.Extractor(data_folder, logs_folder, initialize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the `while` loop below that actually does the work of cleaning and loading each file into the database. Before running the `while` loop, remember to replace the `username` and `password` fields with the username and password you set up in the steps above--and be sure to add quotes('') around them.\n",
    "\n",
    "Also, if the while loop is interrupted for some reason during the load, don't panic!  The logs folder contains a `files_to_load.txt` file that keeps track of all the files that still need to be loaded into the database.  To re-start the load, simply re-load the extractor above with the argument `initialize=False`.  Then, re-run the while loop below and the load will pick up where it left off.\n",
    "\n",
    "Ready to load?  Okay, go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while extractor.next_file_available():\n",
    "    next_file_data, next_file_name = extractor.get_next_file() # read in the next file\n",
    "    cleaner = cleanNLoad.Cleaner(next_file_data, next_file_name, logs_folder) # clean the data (fix bounding boxes, add centroids, etc.)\n",
    "    cleaned_data = cleaner.clean_data() \n",
    "    loader = cleanNLoad.Loader(cleaned_data, next_file_name, logs_folder) # initialize the loader\n",
    "    loader.get_connection(\"neo4j\", \"localhost\", \"7687\", <username>, <password>) # create a database connection\n",
    "    loader.load_data() # load the data file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
