{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Neo4j for Spatial Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch Neo4j locally using Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a persistent data volume\n",
    "\n",
    "To get started, you'll need to create a persistent data volume that Docker can use to store your database's files.  Creating a Docker volume allows you to persist any data loaded into the database, even if you have to stop, start, or re-run the Docker container housing your database.  Run the following from the command line to create a Docker volume for you Neo4j database:\n",
    "\n",
    "```bash\n",
    "docker volume create neo4j_volume\n",
    "```\n",
    "\n",
    "To check that the volume was created successfully, run the following from your command line:\n",
    "```bash\n",
    "docker volume ls\n",
    "```\n",
    "\n",
    "You should see a volume called `neo4j_volume` listed in the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download database plugins\n",
    "\n",
    "Neo4j has a number of community-supported plugins that provide useful utilities for loading data, running advanced graph algorithms, and managing spatial data.  Download the latest release of each of these plugins from their respective GitHub pages:\n",
    "\n",
    "- Awesome Procedures for Neo4j (APOC): \n",
    "[[Download link](https://github.com/neo4j-contrib/neo4j-apoc-procedures/releases)]\n",
    "[[GitHub main page](https://github.com/neo4j-contrib/neo4j-apoc-procedures)]\n",
    "[[Documentation](https://neo4j-contrib.github.io/neo4j-apoc-procedures/)]\n",
    "\n",
    "- Efficient Graph Algorithms for Neo4j: \n",
    "[[Download link](https://github.com/neo4j-contrib/neo4j-graph-algorithms/releases)]\n",
    "[[GitHub main page](https://github.com/neo4j-contrib/neo4j-graph-algorithms)]\n",
    "[[Documentation](https://neo4j.com/docs/graph-algorithms/current/)]\n",
    "\n",
    "- Neo4j Spatial: \n",
    "[[Download link](https://github.com/neo4j-contrib/spatial/releases)]\n",
    "[[GitHub main page](https://github.com/neo4j-contrib/spatial)]\n",
    "[[User Guide](https://neo4j-contrib.github.io/spatial/)]\n",
    "\n",
    "\n",
    "Each of these plugins downloads as a .jar file.  Take these .jar files and move them to a folder on your computer where you can find them easily.  For this example, we'll assume you're saving them to your user folder inside of a folder called 'neo4j_plugins':\n",
    "\n",
    "/Users/your_username/neo4j_plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the Docker container\n",
    "\n",
    "Now you're finally ready to launch Neo4j using Docker!  Run the following from your command line.  Be sure to replace the file path in brackets (<>) below with the actual path to your neo4j_plugins folder (and remove the brackets):\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "--name neo4j \\\n",
    "-p 7474:7474 -p 7687:7687 \\\n",
    "--mount source=neo4j_volume,target=/data \\\n",
    "-v </Users/your_username/neo4j_plugins>:/plugins \\\n",
    "-e NEO4J_apoc_export_file_enabled=true \\\n",
    "-e NEO4J_apoc_import_file_enabled=true \\\n",
    "-e NEO4J_apoc_import_file_use__neo4j__config=true \\\n",
    "-e NEO4J_dbms_security_procedures_unrestricted=apoc.\\\\\\*,algo.\\\\\\*,spatial.\\\\\\* \\\n",
    "-e NEO4J_dbms_security_allow__csv__import__from__file__urls=true \\\n",
    "neo4j:3.4\n",
    "```\n",
    "\n",
    "What does this command do?  Breaking it down, here's what each argument means:\n",
    "\n",
    "- **-d** : runs the container in \"detached\" mode, so that it keeps running in the background and will not shut off if you close out of your console window\n",
    "- **--name** : the name Docker will give to your container; if you don't specify a name here, Docker will give your container a randomly-generated name\n",
    "- **-p** : these are port mappings, indicating that Docker should forward information going in and out of port 7474 from the Neo4j container to port 7474 on your local machine; the same goes for port 7687\n",
    "- **--mount** : takes the persistent volume named `neo4j_volume` and mounts it into the /data folder inside of the container; this is where the database's data and settings will get stored\n",
    "- **-e**: environment variables that get passed to the database's configuration file on startup; these variables are required to make sure plugins will run correctly\n",
    "- At the very end of the command, you'll notice we list **neo4j:3.4** as the final argument.  This specifies the Docker image and version to run inside of the container, and will download and launch Neo4j version 3.4 (the most current version as of this writing).  If newer versions are available, you can specify `neo4j:latest` to get the most recent version of Neo4j.\n",
    "\n",
    "To check that the container is running, execute the following command in the command line:\n",
    "\n",
    "```docker container ls```\n",
    "\n",
    "You should see something like this, indicating that the container is successfully running:\n",
    "\n",
    "```\n",
    "CONTAINER ID    IMAGE        COMMAND                CREATED         STATUS          PORTS\n",
    "blahblahblah    neo4j:3.4    \"/sbin/tini -g -- /dâ€¦\" 9 seconds ago   Up 8 seconds    0.0.0.0:7474->7474/tcp, 7473/tcp, 0.0.0.0:7687->7687/tcp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neo4j has a web-based access interface that you can view using a web browser.  Launch your web browser of choice and navigate to:\n",
    "\n",
    "```http://localhost:7474/browser```\n",
    "\n",
    "If the container is successfully initialized, you should be able to see a login interface in your web browser.  It will prompt you for a username and password.  Enter ```neo4j``` as both your username and password:\n",
    "\n",
    "![Neo4j browser launch page](img_neo4j/neo4j_browser_launch.png)\n",
    "\n",
    "Then, reset the default admit password to a new password of your choice when prompted:\n",
    "\n",
    "![Neo4j browser launch page password setup](img_neo4j/neo4j_browser_launch_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into the database\n",
    "\n",
    "Now, it's time to load in some data!  \n",
    "\n",
    "\n",
    "Data model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create indexes\n",
    "\n",
    "Prior to loading in any data, let's start off by adding some indexes to the database.  Adding indexes is a critical step, because the presence of indexes can really help improve load time.  We also want to do our best not to load duplicate data when adding data to the database, and indexes can help with this.  When loading in data, we will ask Neo4j to check for any duplicates of tweets, users, places, or hashtags that may be present prior to loading in new records.  If it encounters a tweet that is already present in the database, Neo4j can skip over this tweet and avoid loading a redundant record.  In order to check for duplicates, however, Neo4j first needs to search through all of the existing records on each record load to see what's already present in the database.  This search and insert process goes _much_ more quickly if data is pre-sorted using indexes.  \n",
    "\n",
    "_What happens if we don't add indexes before loading in the data?_  Here is an example of 40 files being loaded into Neo4j installed on a home server.  In this scenario, the first 20 files were loaded prior to the addition of indexes, and the last 20 files were loaded after the addition of indexes:  \n",
    "\n",
    "![visualization of load time before and after adding indexes](img_neo4j/neo4j_load_time_indexes.png)\n",
    "\n",
    "Some of the load time depicted above is due to network latency and processing effort required in the database, but much of the load time can be attributed to the relative efficiency or ineffeciency due to the presence or absence of indexes.  For the first 20 files, you can see that the load time increases at a linear rate, with each file taking consistently longer to load.  For the last 20 files, you can see that the load time immediately drops after the addition of the indexes and stays more consistently flat, regardless of how many additional files we load.\n",
    "\n",
    "To create an index, run the following command in the web admin console for your Neo4j instance.  Copy the command into the console, and then click the \"play\" button to execute the command: \n",
    "\n",
    "```cypher\n",
    "CREATE INDEX ON :Tweet(tweet_id)\n",
    "```\n",
    "\n",
    "![Neo4j create index call](img_neo4j/neo4j_create_index.png)\n",
    "\n",
    "The above command created an index on tweet_id, which is the unique identifier we'll be using to load tweets and check for duplicates.  Next, create an index on user_id, place_id, and hashtag_id to function in a similar manner.  Execute these commands one by one in the Neo4j web admin console:\n",
    "\n",
    "```cypher\n",
    "CREATE INDEX ON :User(user_id)\n",
    "CREATE INDEX ON :Place(place_id)\n",
    "CREATE INDEX ON :Hashtag(hashtag_id)\n",
    "```\n",
    "\n",
    "Finally, add a spatial index for the centroids of the Twitter Places that are present in our tweets.  This will enable some basic spatial query functionality after the data is loaded:\n",
    "\n",
    "```cypher\n",
    "CREATE INDEX ON :Place(centroid)\n",
    "```\n",
    "\n",
    "To check that the indexes have been successfully created, run the following:\n",
    "```cypher\n",
    "CALL db.indexes\n",
    "```\n",
    "\n",
    "![Neo4j results for CALL db.indexes](img_neo4j/neo4j_indexes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute load scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Clean_Load_Scripts as cleanNLoad\n",
    "import secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = '/Users/linkalis/Desktop/twitter_data/data_small_5000_split/'\n",
    "logs_folder = '/Users/linkalis/Desktop/twitter_data/data_small_5000_split/logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize extractor\n",
    "extractor = cleanNLoad.Extractor(data_folder, logs_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extractor: Next file is: 500M_unicode_splitan.txt\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/data_small_5000_split/500M_unicode_splitan.txt\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Session' object has no attribute 'session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-02524e95447e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcleaned_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleanNLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# initialize the loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"neo4j\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneo4j_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneo4j_port\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneo4j_username\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneo4j_pwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# create a db connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/linkalis/GIS8990_DistributedSpatialDatabases/nosql_databases_for_spatial_analysis/Clean_Load_Scripts.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(self, db_type, db_host, db_port, username, pwd, db_name, collection_name)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdb_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"neo4j\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb_connection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeo4jLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_port\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdb_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"elasticsearch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb_connection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElasticSearchLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_port\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/linkalis/GIS8990_DistributedSpatialDatabases/nosql_databases_for_spatial_analysis/Clean_Load_Scripts.py\u001b[0m in \u001b[0;36minitialize_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m             \u001b[0mtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructure_data_for_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Session' object has no attribute 'session'"
     ]
    }
   ],
   "source": [
    "while extractor.next_file_available():\n",
    "    next_file_data, next_file_name = extractor.get_next_file() # read in the next file\n",
    "    cleaner = cleanNLoad.Cleaner(next_file_data, next_file_name, logs_folder) # clean the data (fix bounding boxes, add centroids, etc.)\n",
    "    cleaned_data = cleaner.clean_data() \n",
    "    loader = cleanNLoad.Loader(cleaned_data, next_file_name, logs_folder) # initialize the loader\n",
    "    loader.get_connection(\"neo4j\", secrets.neo4j_host, secrets.neo4j_port, secrets.neo4j_username, secrets.neo4j_pwd) # create a db connection\n",
    "    loader.load_data() # load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
