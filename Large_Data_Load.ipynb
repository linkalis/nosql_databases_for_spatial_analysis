{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Clean_Load_Scripts as cleanNLoad\n",
    "\n",
    "import secrets as secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_folder = '/Users/linkalis/Desktop/twitter_data/twitter_sample_2017_split/'\n",
    "#logs_folder = '/Users/linkalis/Desktop/twitter_data/twitter_sample_2017_split/logs/'\n",
    "\n",
    "data_folder = '/Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/'\n",
    "logs_folder = '/Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/logs/'\n",
    "\n",
    "#data_folder = '/Users/linkalis/Desktop/twitter_data/twitter_sample_5GB_20000_split/'\n",
    "#logs_folder = '/Users/linkalis/Desktop/twitter_data/twitter_sample_5GB_20000_split/logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = cleanNLoad.Extractor(data_folder, logs_folder, initialize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extractor: Next file is: 500M_unicode_splitac.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitac.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitav.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitav.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitbi.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitbi.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitao.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitao.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitaz.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitaz.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitbe.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitbe.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitbd.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitbd.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitan.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitan.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitbh.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitbh.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitaw.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitaw.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitab.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitab.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitai.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitai.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitbc.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitbc.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitae.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitae.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitap.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitap.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitbn.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitbn.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitaq.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitaq.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitad.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitad.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitbb.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitbb.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitah.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitah.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitba.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitba.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitak.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitak.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitbm.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitbm.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitar.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitar.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitag.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitag.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitaf.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitaf.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitas.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitas.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitbl.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitbl.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitaj.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitaj.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitbk.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitbk.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitat.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitat.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitaa.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitaa.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitbg.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitbg.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitax.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitax.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitam.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitam.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splital.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splital.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitay.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitay.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitbf.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitbf.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitau.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitau.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n",
      "Extractor: Next file is: 500M_unicode_splitbj.json\n",
      "Extractor: Reading file: /Users/linkalis/Desktop/twitter_data/twitter_sample_500MB_5000_split/500M_unicode_splitbj.json\n",
      "Extractor: Read 5000 data rows.\n",
      "Cleaner: Finished cleaning records.\n",
      "Connected to ElasticSearch instance.\n",
      "Checking for existence of index called: twitter_small\n",
      "Loader: Loading batch data!\n",
      "Loader: Finished loading records.\n"
     ]
    }
   ],
   "source": [
    "while extractor.next_file_available():\n",
    "    next_file_data, next_file_name = extractor.get_next_file() # read in the next file\n",
    "    cleaner = cleanNLoad.Cleaner(next_file_data, next_file_name, logs_folder) # clean the data (fix bounding boxes, add centroids, etc.)\n",
    "    cleaned_data = cleaner.clean_data() \n",
    "    loader = cleanNLoad.Loader(cleaned_data, next_file_name, logs_folder) # initialize the loader\n",
    "    loader.get_connection(\"elasticsearch\", \"linkylink.net\", \"9200\", db_name=\"twitter_small\")\n",
    "    #loader.get_connection(\"mongodb\", \n",
    "    #                      \"localhost\", \n",
    "    #                      \"27017\", \n",
    "    #                      None, #secrets.mongodb_username, \n",
    "    #                      None, #secrets.mongodb_pwd, \n",
    "    #                      \"twitter_small\", \n",
    "    #                      \"tweets\") # create a database connection\n",
    "    loader.load_batch_data() # load the file's data as a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
