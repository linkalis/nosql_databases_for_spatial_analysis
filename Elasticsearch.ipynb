{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Elasticsearch for Spatial Analysis\n",
    "\n",
    "<span style=\"background:yellow\">Introduction & background on Elasticsearch and document databases...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch Elasticsearch locally using Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elasticsearch contains multiple services/components that need to communicate with each other.  This is hard to accomplish when using isolated Docker containers, as these containers are generally not set up to be mutually accessible to each other.  Instead, it is easier to use Docker Compose, a container orchestration utility that allows you to run multiple, linked services within networked containers that can communicate with each other.\n",
    "\n",
    "```bash\n",
    "docker-compose -f elasticsearch-docker-compose.yml up -d\n",
    "```\n",
    "\n",
    "-f specifies the filename of the .yml file that describes the cluster of services we want to run\n",
    "\n",
    "-d tells Docker Compose to run the cluster in detached mode, so it runs in the background even if you quit your console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "```bash\n",
    "docker volume create elasticsearch_volume\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Create an index and define its mappings\n",
    "\n",
    "PUT twitter_sample\n",
    "{\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"tweet\": {\n",
    "            \"_source\": { \"enabled\": false },\n",
    "            \"properties\": {\n",
    "                \"text\": {\"type\": \"text\" },\n",
    "                \"timestamp_ms\": { \"type\": \"date\", \"format\": \"epoch_millis\" },\n",
    "                \"user\": { \n",
    "                    \"properties\": { \n",
    "                        \"location\": { \"type\": \"text\" },\n",
    "                        \"description\": { \"type\": \"text\" }\n",
    "                    }\n",
    "                },\n",
    "                \"place\": { \n",
    "                    \"properties\": { \n",
    "                        \"name\": { \"type\": \"keyword\" },\n",
    "                        \"full_name\": { \"type\": \"keyword\" },\n",
    "                        \"centroid\": { \"type\": \"geo_point\" },\n",
    "                        \"better_bounding_box\": { \"type\": \"geo_shape\" },\n",
    "                        \"centroid_geohash\": { \"type\": \"geo_point\" }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute load scripts\n",
    "\n",
    "<span style=\"background:yellow\">Explain bulk insert functionality</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Clean_Load_Scripts as cleanNLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = '/Users/linkalis/Desktop/twitter_data/twitter_sample_5GB_split/'\n",
    "logs_folder = '/Users/linkalis/Desktop/twitter_data/twitter_sample_5GB_split/logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extractor = cleanNLoad.Extractor(data_folder, logs_folder, initialize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while extractor.next_file_available():\n",
    "    next_file_data, next_file_name = extractor.get_next_file() # read in the next file\n",
    "    cleaner = cleanNLoad.Cleaner(next_file_data, next_file_name, logs_folder) # clean the data (fix bounding boxes, add centroids, etc.)\n",
    "    cleaned_data = cleaner.clean_data() \n",
    "    loader = cleanNLoad.Loader(cleaned_data, next_file_name, logs_folder) # initialize the loader\n",
    "    loader.get_connection(\"elasticsearch\", \"localhost\", \"9200\", \"twitter_sample\") # create a database connection\n",
    "    loader.load_batch_data() # load the file's data as a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "* Install Elasticsearch with Docker. [Elasticsearch documentation] https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html\n",
    "\n",
    "* Learning Elasticstack. [Packt Publishing]\n",
    "\n",
    "* Building an Elasticstack Index with Python. https://qbox.io/blog/building-an-elasticsearch-index-with-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
